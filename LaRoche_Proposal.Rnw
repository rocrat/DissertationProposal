\documentclass{book}
\usepackage[letterpaper, top=1in, bottom=1.25in, left=1.25in, right=1.25in]{geometry}
\usepackage[colorlinks=true, linkcolor=blue, citecolor=blue]{hyperref}
\usepackage[backend=bibtex,backref=true,hyperref=true]{biblatex}
\addbibresource{proportionality.bib}
\usepackage{amsmath}
\usepackage{setspace}

\title{Dissertation Proposal:\\ Methods for the Analysis of Compositional RNA Sequence Data}
\author{Dominic D LaRoche}

\begin{document}
\maketitle
\tableofcontents

\doublespacing
\chapter[Background]{Background and Introduction to the Problem}

\section{RNA Sequencing Data}
%General information about RNA sequence data: where it comes from and how people use it.
Ribonucleic acid (RNA) plays many important roles in the function of cells including gene transcription and regulation.  RNA has become a major target of investigation for a wide variety of research areas in biology.  RNA can be used to determine if pathogenic cells exhibit differential expression of certain genes as compared to healthy cells. It can be used to identify cancer sub-types and identify news genes for interrogation in the investigation of a disease.  Investigations of RNA in biological samples has, until recently, been conducted in micro-array experiments.  However, a reasonably new technology, RNA-Seq \cite{Wang2009}, offers several advantages over a traditional micro-array experiment and has been rapidly adopted by scientists \cite{Illumina}.  The current research is restricted to the analysis of targeted RNA-Seq data and the unique analytical challenges it creates.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\subsection{RNA Sequencing Technology}
Several general sequence-based methods exist to quantify RNA from a eukaryotic sample.  These include traditional Sanger sequencing of the cDNA \cite{Boguski1994,Gerhard2004} and tag-based methods such as Serial Analysis of Gene Expression (SAGE) \cite{CITEHERE}.  The focus of this research is on Next Generation Sequencing (NGS) data from targeted RNA-Seq platforms.\\  

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\subsection{Process of Collecting and Sequencing RNA}%Make this more specific to targeted extraction free chemistry
%How samples are collected, prepared, and sequenced
RNA is sequenced from finite volumes of tissue or plasma/serum.  In a traditional RNA-Seq experiments RNA must be isolated, purified and converted into double stranded complementary DNA (cDNA) sample libraries prior to sequencing.  There are many methods available for RNA library preparation which vary with respect to the resulting libraries complexity, evenness and continuity of coverage, and accuracy for expression profiling~\cite{Levin2010}.\\

The focus of this research is on extraction-free targeted RNA-Seq.  Extraction free sample preparation enables measurement of \emph{a priori} selected transcripts with greater precision and smaller sample inputs~\cite{CITE}.  This research does not attempt to address the impacts of the various sample library preparation methods other than to note that RNA is obtained from finite, and potentially very small, biological samples.  \\

To sequence the cDNA libraries, platform specific adapters are added to the ends of the cDNA fragments.  Several platforms are available and the specific chemistry differs among them. Several articles have been published comparing these platforms~\cite{Liu2012,Glenn2011} for sequencing RNA.  The differences in platforms, and the resulting differences in data produced by them, is beyond the scope of this research.  Instead we focus on the common features of these platforms and the resulting impact on RNA-Seq data generally.\\

For all NGS-based sequencing platforms, adapted cDNA fragments are immobilized on a proprietary surface (flow cells or beads) with a finite amount of area.  The resulting cDNA templates are then amplified to create clusters of copied cDNA (Illumina) or beads are placed into wells (Roche 454).  Sequences for clonal clusters (wells) are then determined through Sequencing by Synthesis (SBS).  The chemistry for the synthesis also varies by platform but the process involves repeatedly adding a single nucleotide to each template and recording the value of the nucleotide through either fluorescence or light emission. Each cluster then represents the sequence of a single cDNA transcript captured on the surface.  Different platforms allow a different total number of transcripts to be sequenced in a single sequencing run, ranging from 70,000 to 5 billion.  This research is limited to evaluating data produced on Illumina sequencers which are the most widely adopted NGS technology.\\

The number of reads in a sequencing run allocated to a sample is referred to as the read depth.  Read depth has been associated with data quality~\cite{Tarazona2011,Haas2012,Liu2013,Liu2014} with greater read-depth associated with higher precision. There is a trade-off between cost, replication, and read-depth for any given experiment~\cite{Liu2014} because a given sequencing run has a limited number of reads to allocate to individual samples.\\

Once sequences have measured by the sequencer they are aligned to a genome and various quality metrics are calculated.  Alignment typically proceeds through a greedy algorithm implemented in programs such as Bowtie~\cite{Langmead2009}. Several different sequences might align with varying accuracy to the same gene and these must be counted in a way which accounts for the uncertainty of the alignment. In targeted sequencing the alignment is greatly simplified because the targets are known and consist of a much smaller set of possible sequences.\\   

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\subsection{Compositional Properties of RNA Sequence Data}
\label{sec:rnaSampProp}
%What are the consequences of the process and the nature of RNA? i.e. poisson, neg-bin, and sum constraints.  Factors affecting sequencing
%two sum constraints in RNA seq data: one related to the size of the sample (sample bucket) and another related to the number of mapped reads (sequencing depth bucket)
Previous authors have identified the relative abundance nature of RNA sequencing data~\cite{Robinson2010}.  RNA sequence data are  subject to two constraints: 1) the number of RNA transcripts that can fit into the finite sample collected, and 2) the number of available reads of those transcripts available in a sequencing run. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Principles of Compositional Data Analysis}
Compositional data are non-negative data which are subject to a sum constraint, i.e. all the elements must sum to unity.  This simple constraint has some important consequences for many standard statistical methodologies including correlation and regression.  Compositional data contain only relative information, i.e. the information about any individual component, or group of components, is relative to the other components and no absolute information about the absolute value of the component.  For example, if we know that 20\% of the food in a refrigerator is composed of fruit we do not know how much total fruit there is.  If the refrigerator is full then there will be substantially more fruit than if the refrigerator is nearly empty.  It is, therefore, important to recognize the types of inferences that can be made from compositional data, e.g. no inference can be made on the actual abundances.\\

Potential problems associated with compositional data were identified as early as 1897 by Pearson who noted that spurious correlations can be induced through ratios of independent variables, e.g. if $X$, $Y$, and $Z$ are uncorrelated then $X/Z$ and $Y/Z$ will be correlated. Despite the fact that compositional data naturally arises in a wide variety of scientific disciplines, a general method for analysis of compositional data was not developed until John Aitchison published his seminal book in 1986.  Aitchison outlines some basic principles for compositional data analysis (section~\ref{subsec:fund}) and provides some analysis tools for compositional data which conform to these principles (section~\ref{subsec:methods}).  Additional methodology has been developed by a number of authors in the 29 years since the publication of Aitchison's book, although a number of problems remain. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\subsection{Fundamental Principles}
\label{subsec:fund}
Aitchison outlined a set of fundamental principles to which all methods for compositional data should adhere~\cite{Aitchison1986}.  These principles are outlined below.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\subsubsection{Scale Invariance}
Scale invariance requires that the results of a statistical procedure should not depend on the scale used.  Any meaningful function $x$ of a composition $w$ must satisfy:

$$f(pw) = f(w) \text{, for every }p>0.$$

Aitchison notes that any meaningful (scale-invariant) function of a composition can be expressed in terms of ratios of the components of the composition.  For example, any method used for compositional data should not give different results whether the composition is given as proportions, percentages, parts per million, or any other scale.\\

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Sub-compositional Coherence}
Sub-compositional coherence requires that the results of a statistical procedure on a subset of components from a composition should depend only on the data contained in that subset.  A sub-composition is defined as the (1, 2, ..., $C$) parts of a $D$-part composition $\left[x_1, ..., x_D\right]$:

$$\left[s_1, ..., s_c\right]=\frac{\left[x_1, ..., x_c\right]}{\left(x_1 + ... + x_c\right)}$$

Any changes in components $\left[x_{c+1}, ..., x_D\right]$ should not have an impact on the inference from the sub-composition.  For example, if we measure the number of reads of 14 mRNA sequences from a sample that contains 4,000 unique mRNA sequences the inference we obtain from those 14 sequences should not be affected by the expression level of any of the other 3,986 sequences.\\ 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\subsubsection{Permutation Invariance}
Permutation invariance requires that the results of a statistical procedure should not depend on the ordering of the components. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\subsection{Statistical Methods for Compositional Data}
\label{subsec:methods}
\subsubsection{The Simplex}
Traditional statistics is concerned with making inferences from points in $R^D$.  However, the sample space for compositions is restricted to the \emph{Simplex}, $S^D$ because of the sum constraint.  This fundamental difference in sample space necessitates an alternative methodology and renders inference from traditional regression and correlation meaningless.  Aitchison (1986) developed much of the current methodology for compositional data through careful examination of the algebraic-geometric structure of the simplex.\\

It is typical to transform compositional data to the \emph{unit simplex} by dividing each component by the sum of components such that the sum of transformed components is equal to 1: 

\begin{equation}
\mathcal{C}\left[ x_1 ... x_d \right] = \left[ x_1 ... x_d \right]/ \sum_{i=1}^D x_i
\label{closure}
\end{equation}

The notation $\mathcal{C}[\cdot]$ is termed the \emph{closure operation} and scales a composition x to the unit simplex.
%use the unit simplex throughout?
There are two fundamental operations frequently used in $R^D$ for which Aitchison defined equivalent operations in the simplex: 1) translation, and 2) scalar multiplication.  \\

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\subsubsection{Perturbations}
\label{subsubsec:perturbation}
Aitchison identified the need for an operation in the simplex equivalent to $X=x+t$, the translation $t$. This operation, defined as a \emph{perturbation} and denoted by $\oplus$, takes the form:

$$X = p \oplus x = \frac{\left[ p_1x_1...p_Dx_D \right]}{\left( p_1x_1 + ... + p_Dx_D \right)} = \mathcal{C}\left[ p_1x_1...p_Dx_D \right]$$

where, $p$ is the perturbation which translates $x$ to $X$ and $\mathcal{C}[\cdot]$ is the \emph{closure} operation which scales the composition to the unit simplex.  The perturbation operator leads to several other useful metrics in the simplex such as the distance between two compositions (see~\ref{subsubsec:distance}).  As well as for characterizing the imprecision or error around a measurement:

$$x_n = \Upsilon \oplus p_n  \ \ (n=1, ... , N),$$

where the $x_n$ are the observed measurements, the $p_n$ are independent error perturbations characterizing the imprecision,  and $\Upsilon$ is the true underlying composition.   

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\subsubsection{The Power Operation}
\label{subsubsec:power}
Like perturbation is the simplical equivalent of translation, Aitchison defined the power operation as the simplical equivalent of multiplication.  For any real number $a \in R^1$ and any composition $x \in S^D$ the power transform of $x$ is defined as:

$$X = a \otimes x = \mathcal{C} \left[x_1^a ... x_D^a \right].$$

The power transformation enables a compositional form for regression between a fixed variable $v$ and a composition $x$:

$$ x= \Upsilon \oplus \left\{ log v \otimes \beta \right\} \oplus p.$$

In this formulation $\beta$ is composition analogous to regression coefficients and $p$ is a perturbation analogous to an error term in regression.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Log-ratio Analysis}
\label{subsubsec:ratio}
In order to satisfy the scale invariance of compositional data it is typical to work on ratios of the components.  Furthermore, since the sample space of ratios of positive numbers is not in the whole of real numbers, it is typical to work in the logarithms of ratios.  The log-ratio transformation maps the composition to the whole of real numbers  Three popular transformation exist for a $D$-part composition: 1) additive log-ratio, 2) centered log-ratio, and 3) ilr. The alr transformation is defined as:

\begin{equation}
alr(X) = [log(\frac{x_1}{x_D})\ log(\frac{x_2}{x_D})\ ...\ log(\frac{x_{D-1}}{x_D})]
\end{equation}

and reduces the dimension of the compositional vector from $D \rightarrow D-1$. The choice of divisor does not impact the inference made from the data~\cite{Aitchison1986}, although the divisor must be reliably greater than 0 in all measurements.  Moreover, since the transformation is 1:1, inferences on the ratios can be made back to the parts of the composition.  Parts of the composition with 0 values will return $log(0/x_D) = log(0) = -\infty$.  While this preserves the rank order of the magnitudes of the components it is not useful in application.\\

Since the ALR transformation reduces the dimension of the compositional vector and does not treat all elements of the composition equally, Aitchison proposed the \emph{centered log-ratio} transformation (\emph{clr}).  The clr is defined as:
\begin{equation}
clr(X) = [log\left( \frac{x_1}{g(x)}\right),\ ...\ ,log\left(\frac{x_D}{g(x)}\right)],
\end{equation}

where $g(x)$ is the geometric mean of $X$.  The clr transformation takes $S^D \rightarrow U^D$, where $U^D$ is a hyper-plane of $R^D$, thereby preserving the dimension of $X$ and providing symmetric treatment of all elements of $X$.  The CLR transformation will fail if any $x_i$ is equal to 0. This is because the geometric mean, defined as $g(x) = \left(\prod_{i=1}^D x_i \right)^{1/D}$, will equal 0.  The CLR will then become, 

$$clr(x) = log\left( \frac{x_1}{0}\right) = log(x_1) - log(0) = log(x_1) + \infty .$$

For any $x_i > 0$,
$$clr(x_i) = log(x_i) + \infty = \infty$$
whereas for any $x_i = 0$,
$$clr(x_i) = log(0) + \infty = -\infty + \infty,$$
which is indeterminate.  Both log-ratio transformations proposed by Aitchison fail to accommodate zeros so various mechanisms have been proposed for handling zeros while maintaining the essential properties of compositional data analysis (see section \ref{sec:zeros}).\\ 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 
\subsubsection{Distance Between Compositions}
\label{subsubsec:distance}
The compositional geometry must be accounted for when measuring the distance between two compositions or finding the center of a group of compositions~\cite{Aitchison2000}.  Aitchison~\cite{Aitchison1992} outlined several properties for any compositional difference metric which must be met: scale invariance, permutation invariance, perturbation invariance (similar to translation invariance for Euclidean distance), and subcompositional dominance (similar to subspace dominance of Euclidean distance).  The scale invariance requirement is ignorable if the difference metric is applied to data on the same scale (which is generally not satisfied in raw RNA-seq data). The permutation invariance is generally satisfied by existing methods~\cite{Martin-Fernandez1998}. However, the perturbation invariance and subcompositional dominance are not generally satisfied. \\

Aitchison~\cite{Aitchison1986, Aitchison1992} suggests using the sum of squares of all log-ratio differences.  Billheimer, Guttorp, and Fagan~\cite{Billheimer2001} use the geometry of compositions to define a norm which, along with the perturbation operator defined by Aitchison~\cite{Aitchison1986}, allow the interpretation of differences in compositions.  Martin-Fernandez et al.~\cite{Martin-Fernandez1998} showed that applying either Euclidean distance or Mahalanobis distance metric to CLR transformed data satisfies all the requirements of a compositional distance metric. Euclidean distance on CLR transformed compositions is referred to as Aitchison distance:

$$d_A(x_i, x_j) = \left[\sum_{k=1}^D \left( log \left(\frac{x_{ik}}{g(x_i)} \right) - log \left(\frac{x_{jk}}{g(x_j)} \right) \right)^2  \right]^\frac{1}{2}$$

or 

$$d_A(x_i, x_j) = \left[\sum_{k=1}^D \left( clr(x_{ik}) - clr(x_{jk}) \right)^2  \right]^\frac{1}{2}$$


%alr - could this be sensitive to the choice of denominator?  I.e. how much will results be affected if the denominator is a highly variable probe?
%look into 'compositional independence'
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\subsubsection{Zeros and Missing Components}
\label{sec:zeros}
Many compositional methods do not work with missing values, or zeros, such as the ALR or CLR transformations as noted above.  Because of this, several strategies for handling missing values and zeros through imputation have been proposed.  Missing values are classified into missing completely at random (MCAR), missing at random (MAR), and missing not at random (MNAR).  These classifications have the same definitions as their non-compositional counterparts. However, imputation methods for non-compositional data are not immediately applicable due to the lack of independence between the components.  Missing values, in the traditional sense, are not typical for RNA-seq data so I do not elaborate on these methods here instead focusing on the handling of zeros.\\

In RNA-seq data, zeros can naturally arise for multiple reasons.  If reads for a probe cannot exist because of known reasons, e.g. an exogenous negative control, then a 0 for this probe would be considered a \emph{structural zero}.  If a probe is assigned 0 reads for a sample because that gene is not expressed in the sample then this would be a \emph{true zero}. Finally, if a probe is assigned 0 reads for a sample because it has very low expression, then this would be considered \emph{Below Detection Limit} (BDL).  For many RNA-seq technologies there is no way to differentiate between true zeros and BDL zeros in practice as it is impossible to know if increasing the read-depth would eventually result in detection of reads for a gene.\\

Aitchison (1986) proposes several approaches to dealing with zeros in the absence of a one-to-one monotonic transformation which accommodates zeros: amalgamation, imputation with a constant, addition of a constant to every observation, replacing the log-ratio transformation with a modified Box-Cox transformation, and a conditional model which explicitly models the probability of a component having a 0 proportion.  Amalgamation, model-based imputation, and conditional models may all be good solutions for particular analyses goals and data sets but are difficult or impossible to apply universally to individual samples, a necessary requirement for clinical utility.\\


The addition of a constant to every observation (as in the case of the Law et al.~\cite{Law2014} log2(Counts per Million) transformation) is a tempting option for its simplicity and ease of implementation for individual samples.  However, this additive transformation alters the proportionality within a composition i.e. the ratio $\frac{a}{b} \ne \frac{a+c}{b+c}\ \forall a, b, c \ne 0$.  For the CLR transformation the addition of a constant, $c$ to every observation will reduce the variation in the clr transformed data as can be seen in the limit as $c \rightarrow \infty$, through repeated applications of l'Hopital's rule, it can be shown that:
$$lim_{c \rightarrow \infty} \frac{x_i + c}{\left(\prod_{i=1}^D (x_i + c)\right)^{1/D}} = 0\ \forall \ x_i \in X$$

Since each element of the clr transformed data will converge to a constant the variance of the composition will also converge to 0. Also, as $c \rightarrow 0$, the zero elements of the composition will approach $-\infty$ and these components may have undue leverage on downstream analyses. The log-ratio transformation is clearly sensitive to the choice of constant.\\

Martin-Fernandez et al.~\cite{Martin-Fernandez2000} address this issue through an additive-multiplicative hybrid transformation :
\begin{equation}
r_j = \left\{
\begin{array}{ll}
c_j, & \text{ if } x_j = 0,\\
x_j(1-\sum_{k|x_k=0}c_k), & \text{ if } x_j > 0\\
\end{array}
\right.
\end{equation}

This transformation is additive on the zero components but multiplicative on the non-zero components.  It has several advantages over the simple additive transformation including: 1) perturbation invariance, 2) power transformation invariance, and 3) sub-composition invariance. Importantly, if all $c_j = c$, the Aitchison distance between two transformed data sets does not depend on $c$.\\

The choice of $c$ can be different for each zero component but determining the appropriate value for each 0 in a single sample would be challenging and would likely provide a limited benefit for samples with a relatively small proportion of 0 components.  Martin-Fernandez et al. recommend using 0.55 the threshold value as originally suggested by Sanford et al.~\cite{Kiers2000, Sanford1993}. The threshold value for RNA-seq data must account for read depth since a 0 in a sample with a library size of 1 thousand reads would potentially not be 0 if the total number of reads was increased to 1 million.  Therefore, I define the threshold value for a sample as $\delta = \frac{1}{\text{Total Reads}}$, and $c = 0.55 \times \delta$.\\%would be $.55 \times 1$ read since 1 read is the smallest measurement able to be recorded. %hmmmm this doesn't account for read depth 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Sub-Compositions}
\label{subsec:subcomp}

It is often desirable to evaluate only a portion of the initial set of genes measured, e.g. when comparing two assays with different but overlapping probe sets or when interrogating  a subset of oncogenes from a larger assay.  It is then necessary to ensure that the resulting sub-composition does not depend on the other components in the initial composition such that variations in a component outside the sub-composition do not affect inferences made from the sub-composition.  I.e. the resulting sub-composition should adhere to the principle of sub-compositional coherence (see~\ref{subsec:fund}).  In order to ensure the sub-composition is independent of the omitted values from the full composition.\\

Sub-compositional coherence can be accomplished through the formation of the sub-composition itself.  In forming a $c$ dimensional sub-composition we are transforming the composition from $\mathcal{S}^D \rightarrow \mathcal{S}^c$ (with $c < D$).  Aitchison~\cite{Aitchison1986}~ formalizes the formation of a $c$-dimensional sub-composition $x_s$ from a $D$-dimensional composition $x$ as 
$$x_s = \mathcal{C}(Sx),$$ 
where $S$ is a $c\times D$ selecting matrix and $\mathcal{C}(\cdot)$ is the closure operation.  Under the assumption that all of the original components of the composition were independent, the resulting sub-composition will not depend on the values of the original composition.  Furthermore, the formation of sub-compositions in this way leads to 3 useful properties: 1) the ratio of any two components from the sub-composition is identical to the ratio of the two components in the full composition, 2) the resulting sub-composition can be interpreted as resulting from a linear projection and 3) the resulting sub-compositions will be on the same scale.\\

Aitchison~\cite{Aitchison1986} defines \emph{complete subcompositional independence} for a composition if ``sub-compositions formed from any partition of the composition form an independent set."  \\

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section[Current RNA-Seq Methodology]{Current RNA-Seq Methodology with Respect to Compositional Data Methods and Theory}


\subsection{Counts per Million (CPM) Transformation}
The log Counts per Million (CPM) transformation is a simple as commonly used standardization method and is implemented in the R package limma~\cite{Law2014}.  The CPM transformation standardizes each read count with the total number of reads allocated to the sample (library size):

\begin{equation}
log_2 \left(\frac{r_{gi}+0.5}{t_i+1} \times 10^6 \right),
\label{cpm}
\end{equation}

where $r_{gi}$ is the number of sequence reads for each probe ($g$) and sample ($i$), (scaled to avoid zero counts), adjusted for the number of mapped reads (library size) for each sample $t_i$ (scaled by a constant 1 to ensure the proportional read to library size ratio is greater than zero).\\

The counts per million transformation is a compositional closure operation, similar to~\ref{closure}, which has been modifed to accomodate zeros (assuming zeros occur as a result of insufficient sensitivity, see section~\ref{sec:zeros}) and rescaled by $10^6$.  At the surface, the primary difference between the CPM transformation proposed by Law et al. (2014) and the CLR transformation proposed by Aitchison (1986) is that the CPM transformation uses the sum of the components as the denominator whereas the CLR transformation uses the geometric mean of the components as the denominator.  This difference, however minor, has important implication for the interpretation of the resulting transformation.\\

The CLR transformation of a $D$-dimensional composition $\mathbf{X}$ can be acheived through the matrix operation:

\begin{equation}
CLR(\mathbf{X}) = G_D \text{ log}(\mathbf{X}), 
\label{CLRmat}
\end{equation}

where $G_D  = I_D - D^{-1}J_D$ with $I_D$ the $D \times D$ identity matrix and $J_D$ a $D \times D$ matrix of 1's.  The matrix $G_D$ is an idempotent linear transformation and, therefore, a projection which takes a $D$-dimensional composition from $\mathcal{S}^d$ to  $\mathcal{R}^d$.  Recognizing the CLR as a projection from the simplex space to Euclidean space has important implications for the application of traditional statistical methods to the transformed data.\\

The CPM transformation can be simplified to the log of the compositional closure operation by removing the multiplication by $10^6$ and the addition of constants to both the numerator and denominator of the ratio.  The resulting operation, $CPM*$ can then be achieved through the matrix operation:

\begin{equation}
CPM*(\mathbf{X}) = log( C_N \mathbf{X}),
\label{CPMmat}
\end{equation}

where $C_N$ is a $N \times N$ matrix with the inverse of the compostition (sample) totals along the diagonal.  From equations \ref{CLRmat} and \ref{CPMmat} it becomes obvious that in the CLR transformation the log transformation is applied directly to X, whereas in the CPM transformation the log transformation is applied only after applying the closure operation.  Less obvious is that the matrix $C_N$ does not satisfy the properties of a projection matrix, namely $C_N$ is not idempotent.  This means the CPM operation cannot be interpreted as a projection.  In fact, without the scaling multiplier ($10^6$), the CPM operation simply replaces the positivity constraint on the data with a negativity constraint.\\


The geometric mean as the denominator in the CLR transformation arises naturally from the log transformation of X.  Dividing by the geometric mean is equivalent to subtracting the mean of the log-transformed components from each log-transformed component; thereby centering the data (equation~\ref{meanLog}).

\begin{align}
CLR(x_i) &= log\left(\frac{x_i}{g(\mathbf{x})} \right)\\
 &= log(x_i) - log(g(\mathbf{x})) \\
 &= log(x_i) - \frac{1}{D}log(\prod \mathbf{x}) \\ 
 &= log(x_i) - \frac{\sum_{j=1}^D log(x_j)}{D}
\label{meanLog}
\end{align}


The simplified CPM does not have a similar interpretation.  Rather, the CPM subtracts the log of the sum of un-transformed components which has no clear interpretation.

\begin{align}
CPM*(x_i) &= log\left(\frac{x_i}{\sum \mathbf{x} })\\
  &= log(x_i) - log(\sum \mathbf{x})
\label{logTotal}
\end{align}


%%%%Focus on the difference in geometry between the cpm projection and the CLR projection.  Is the CPM even a projection? - Doesn't appear to be
%
This difference plays an important role in principal components analysis (PCA) and the measurement of distance.  With respect to PCA, the centering acheived through the CLR transformation . \\


%write out what the covariance matrix is using the total rather than the geometric mean, then work out how this would affect measures of distance and correlation

Both the CPM and the CLR transformations suffer from the lack of subcompositional coherance.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\subsection{Median Normalization}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\subsection{Trimmed Mean of M-values Normalization Method}
Robinson and Oshlack (2010) primarily focused on the mapped read constraint when developing their Trimmed-Mean of M-values (TMM) normalization method for RNA sequence data.  Like many others~\cite{Anders2010}, they also assume that the majority of genes in an assay are not differentially expressed.  For sequencing data Robinson and Oshlack first define the gene-wise log-fold-changes as:

$$M_g = log_2 \frac{Y_{gk}/N_{k}}{Y_{gk\prime}/N_{k\prime}},$$

where $Y_{gk}$ is the read count for gene $g$ in sample $k$ (here we assume 1 library for each sample) and $N_k$ as the total number of reads for sample $k$.  They then define the absolute expression levels as:

$$A_g = \frac{1}{2}log_2\left(Y_{gk}/N_k \cdot Y_{gk\prime}/N_{k\prime} \right)\text{ for }Y_{g\bullet} \ne 0,$$

assuming the absolute expression level is the same for the two samples.  Both the $M$-values and $A$-values are trimmed removing the upper and lower 30\% of the $M$-values and the upper and lower 5\% of the $A$-values (although these values are defaults and can be tailored for a given experiment).  The resulting normalization factor for sample $k$ is then a weighted average of the $M$-values:

$$log2\left( TMM_k^r \right) = \frac{ \sum_{g \in G} w^r_{gk}M^r_{gk}}{\sum_{g \in G} w^r_{gk}}$$

where

$$M^r_{gk} = log_2\frac{Y_{gk}/N_{k}}{Y_{gr}/N_{r}}, \ Y_{gk}, Y_{gr} > 0\text{, for reference sample }r, $$

and the weights, $w^r_{gk}$, are defined as:

$$w^r_{gk} = \frac{N_k-Y_{gk}}{N_kY_{gk}} + \frac{N_r-Y_{gr}}{N_rY_{gr}}, \text{ for } Y_{gk}, Y_{gr} > 0.$$

The weights are a result of taking the inverse of the approximate asymptotic variance using the delta method~\cite{Casella2002}.  Note that these calculations omit any genes for which either observed read count is 0; these observations are generally removed by the trimming procedure.\\

The TMM normalization method attempts to derive a single value, $f$, such that $S_k = f \cdot S_{k\prime}$, where $S_k$ is the (unobserved) total count for sample $k$.  Unfortunately, this does not adequately account for the compositional nature of the data.  In particular, the authors assume that the expression levels will be the same among samples for the majority of genes (probes).  However, if we view the data as a composition, even if only a small number of genes differ with respect to expression level then all of the probes will differ with respect to what we actually observe, their \emph{proportion} of the sample. The authors correctly identify that some probes will be under-represented, even if their absolute expression remains unchanged, in samples with a large total RNA output as compared to samples with a smaller total RNA output.  This is because these probes will constitute a smaller proportion of the total number of reads, even if the absolute number will not have changed.\\

The authors do not explicitly reference Aitchison, or any other compositional data publications, but their method relies heavily on these methods.  The TMM operation first converts all samples to the unit simplex by dividing each gene specific read count by the total counts for that sample ($Y_{gk}/N_k$). The full set of M-values calculated from these compositions represent the perturbation, $p$ from a reference sample to another.  However, the M-values are trimmed so $p$ is incomplete and we are now in a subcompositional sample space.  The assumption that most genes are not differentially expressed leads to the authors to use a weighted average of the M-values ($p_i$'s) to determine a single correction factor which can translate one composition to another.  This method, therefore, then assumes $p_i = p_j$ for \emph{most} of the genes $i$ and $j$ in the trimmed set.  \\

The authors fail to formulate the problem in terms of the components of a composition, instead, believing that inferences can still be made on absolute abundances.  This is clearly evidenced in their definition of the $A_g$'s, which they term the `absolute abundances' for each gene in the sample.  As stated in section \ref{sec:rnaSampProp},  RNA sequence data is compositional in nature and, as such, inferences on the absolute abundances are not possible.\\



%toy example here?

\section{Proposed Research}

\subsection{Composition based quality control for targeted RNA-Seq}

The rapid rise in the use of RNA sequencing technology (RNA-seq) for scientific discovery has led to its consideration as a clinical diagnostic tool.  However, as a new technology the analytical accuracy and reproducibility of RNA-seq must be established before it can realize its full clinical utility~\cite{SEQC/MAQC-IIIConsortium2014,VanKeuren-Jensen2014}. Recent studies evaluating RNA-seq have found generally high intra-platform and inter-platform congruence across multiple laboratories~\cite{Li2013, tHoen2013, SEQC/MAQC-IIIConsortium2014}.  Despite these promising results, there is still a need to establish reliable diagnostics, quality control metrics and improve the reproducibility of RNA-seq data.  Understanding, and capatilizing on, the relative frequency nature of RNA-Seq data provides tools for identifying batch effects, creating quality control metrics, and improving reproducibility.\\

%Targeted sequencing vs traditional sequencing 
This research is focused on developing diagnostics for targeted RNA-Seq.  Targeted sequencing allows researchers to efficiently measure transcripts of interest for a particular disease by focusing sequencing efforts on a select subset of transcript targets.  Targeted sequencing offers several benefits over traditional whole-transciptome RNA-Seq for clinical use including the elminiation of amplification bias, reduced sequencing cost, and a simplified bioinformatics workflow.  However, traditional RNA-Seq and targeted RNA-Seq data share many of the same properties so the methods described here should be easily extensible to traditional RNA-Seq.\\

\subsection{Paper 2- Compositional data for biologists}


\subsection{Paper 3- Telescoping amalgamations}







\printbibliography
\end{document}